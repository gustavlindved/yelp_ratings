{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "One_hot_yelp.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ge38EN4NEjE5",
        "colab_type": "code",
        "outputId": "cd6e9e22-ff6b-40ca-978b-6949fe6bb391",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 80
        }
      },
      "source": [
        "# Import packages\n",
        "import os, re, string, time\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from torchtext import data\n",
        "from sklearn.model_selection import train_test_split\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from torchtext.vocab import GloVe\n",
        "import torch\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "import torch.nn as nn\n",
        "from torch.optim.lr_scheduler import StepLR, ReduceLROnPlateau"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<p style=\"color: red;\">\n",
              "The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n",
              "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n",
              "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
              "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ocp-ZUwHDWS2",
        "colab_type": "code",
        "outputId": "83086990-de9c-4b91-a2a5-ba42fdd46f66",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 238
        }
      },
      "source": [
        "# Mount google drive to colab to import data\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')\n",
        "\n",
        "os.chdir('gdrive/My Drive/Colab Notebooks/Yelp')\n",
        "!ls"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n",
            "'Copy of One_hot_yelp.ipynb'\n",
            " One_hot_yelp.ipynb\n",
            " Performance.gsheet\n",
            " Running_copy_binary.ipynb\n",
            " yelp_academic_dataset_review_50k.json\n",
            " yelp_academic_dataset_review.json\n",
            " yelp_academic_dataset_review_small.json\n",
            " yelp_academic_dataset_review_very_small.json\n",
            " Yelp_binary.ipynb\n",
            " Yelp_linear_regression.ipynb\n",
            " Yelp_ordinal_approach.ipynb\n",
            " Yelp_rescale.ipynb\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZWYA4_tKEq9G",
        "colab_type": "code",
        "outputId": "aa3ef2e4-9025-44b0-eef6-4030ef187ac7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "# Load data\n",
        "df = pd.read_json(path_or_buf='yelp_academic_dataset_review.json',lines=True)\n",
        "\n",
        "# Keep only reviews and score\n",
        "df = df[['stars','text']]\n",
        "\n",
        "# Print size of data\n",
        "print('Number of reviews before trimming:', len(df))\n",
        "\n",
        "# Limit size of data set (to avoid awkward ends)\n",
        "limit = 229000\n",
        "df = df.iloc[0:limit]\n",
        "print('Number of reviews after trimming:', len(df))\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of reviews before trimming: 229907\n",
            "Number of reviews after trimming: 229000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bcnxeJ7rKNoU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Preprocess reviews\n",
        "def preprocess_text(sen):\n",
        "  #Make all lower case\n",
        "  sen = sen.lower()\n",
        "\n",
        "  # Remove digits\n",
        "  sen = re.sub(r'\\d+', '', sen)\n",
        "\n",
        "  # Remove punctuation\n",
        "  sen = sen.translate(str.maketrans('', '', string.punctuation))\n",
        "\n",
        "  # Remove newlines\n",
        "  sen = re.sub(r'\\n', ' ', sen)\n",
        "\n",
        "  return sen\n",
        "  \n",
        "X = []\n",
        "sentences = list(df['text'])\n",
        "for sen in sentences:\n",
        "    X.append(preprocess_text(sen))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dbrfpDpbA_Pj",
        "colab_type": "code",
        "outputId": "5e906650-4e58-41c1-ff0c-9d3af420a4ae",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 279
        }
      },
      "source": [
        "# Examine ratings and make into one-hot encoding\n",
        "scores = np.array(df['stars'])\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "from matplotlib.ticker import PercentFormatter\n",
        "\n",
        "plt.hist(scores, weights=np.ones(len(scores)) / len(scores))\n",
        "\n",
        "plt.gca().yaxis.set_major_formatter(PercentFormatter(1))\n",
        "plt.xlabel(\"Number of stars\")\n",
        "plt.xticks((1,2,3,4,5) ,('1', '2', '3', '4', '5'))\n",
        "plt.show()\n",
        "\n",
        "#One-hot encoding\n",
        "scores = scores - 1\n",
        "from keras.utils import to_categorical\n",
        "scores = to_categorical(scores)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYMAAAEGCAYAAACHGfl5AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "coa9znkMBwp9",
        "colab_type": "code",
        "outputId": "96e78216-825a-46bc-d2c3-20cdccda1c9f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "# Split data into train, test and validation\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, scores, test_size=0.20, random_state=42)\n",
        "X_test, X_val, y_test, y_val = train_test_split(X_test, y_test, test_size=0.5, random_state=42)\n",
        "\n",
        "print(\"Size of train data: {}\".format(len(X_train)))\n",
        "print(\"Size of validation data: {}\".format(len(X_val)))\n",
        "print(\"Size of test data: {}\".format(len(X_test)))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Size of train data: 183200\n",
            "Size of validation data: 22900\n",
            "Size of test data: 22900\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SXT2btTkCGP2",
        "colab_type": "code",
        "outputId": "791fbe09-46bd-41d6-e670-cca7c672b611",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# Tokenize reviews\n",
        "tokenizer = Tokenizer(num_words=20000)\n",
        "tokenizer.fit_on_texts(X_train)\n",
        "\n",
        "X_train = tokenizer.texts_to_sequences(X_train)\n",
        "X_test = tokenizer.texts_to_sequences(X_test)\n",
        "X_val = tokenizer.texts_to_sequences(X_val)\n",
        "\n",
        "vocab_size = len(tokenizer.word_index) + 1\n",
        "print('Vocab size is', vocab_size) # But we only keep then amount specified in num_words"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Vocab size is 186446\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oW03uDyCTyc_",
        "colab_type": "code",
        "outputId": "ba92987c-a648-41ec-82ef-f8482880a2e7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 432
        }
      },
      "source": [
        "# Check the lengths of reviews (in words)\n",
        "reviews_len = [len(x) for x in X_train]\n",
        "pd.Series(reviews_len).hist()\n",
        "plt.xlabel(\"Length of review\")\n",
        "plt.ylabel(\"Frequency\")\n",
        "plt.show()\n",
        "\n",
        "pd.Series(reviews_len).describe()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZEAAAEGCAYAAACkQqisAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nUm+GiCSpN0NEktTb/we0/WTQ+dreOgAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "count    183200.000000\n",
              "mean        127.096239\n",
              "std         110.992203\n",
              "min           0.000000\n",
              "25%          52.000000\n",
              "50%          97.000000\n",
              "75%         168.000000\n",
              "max         990.000000\n",
              "dtype: float64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eqG78oegCRM1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Padding\n",
        "maxlen = 200\n",
        "\n",
        "X_train = pad_sequences(X_train, padding='pre', maxlen=maxlen)\n",
        "X_test = pad_sequences(X_test, padding='pre', maxlen=maxlen)\n",
        "X_val = pad_sequences(X_val, padding='pre', maxlen=maxlen)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t3P-eeVZVnDw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Create Tensor datasets\n",
        "train_data = TensorDataset(torch.from_numpy(X_train), torch.from_numpy(y_train))\n",
        "valid_data = TensorDataset(torch.from_numpy(X_val), torch.from_numpy(y_val))\n",
        "test_data = TensorDataset(torch.from_numpy(X_test), torch.from_numpy(y_test))\n",
        "\n",
        "# Dataloaders\n",
        "batch_size = 50\n",
        "\n",
        "train_loader = DataLoader(train_data, shuffle=True, batch_size=batch_size)\n",
        "valid_loader = DataLoader(valid_data, shuffle=True, batch_size=batch_size)\n",
        "test_loader = DataLoader(test_data, shuffle=True, batch_size=batch_size)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hm2StMcMV425",
        "colab_type": "code",
        "outputId": "f9c3d017-926c-446c-b874-699b91bf23c3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "# Let's have a look at the input and target\n",
        "dataiter = iter(train_loader)\n",
        "sample_x, sample_y = dataiter.next()\n",
        "print('Sample input size: ', sample_x.size()) # batch_size, seq_length\n",
        "print('Sample input: \\n', sample_x)\n",
        "print()\n",
        "print('Sample label size: ', sample_y.size()) # batch_size\n",
        "#print('Sample label: \\n', sample_y)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Sample input size:  torch.Size([50, 200])\n",
            "Sample input: \n",
            " tensor([[   0,    0,    0,  ...,  658,  209,  258],\n",
            "        [   0,    0,    0,  ...,    9,    5,   51],\n",
            "        [   0,    0,    0,  ..., 1819,    2,  345],\n",
            "        ...,\n",
            "        [   0,    0,    0,  ..., 5503,    7, 9447],\n",
            "        [7134,    2,    3,  ..., 8062,    5,   37],\n",
            "        [   0,    0,    0,  ...,  779,   72, 1642]], dtype=torch.int32)\n",
            "\n",
            "Sample label size:  torch.Size([50, 5])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CmZKrB9OV46m",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Net(nn.Module):\n",
        "    def __init__(self, vocab_size, output_size, embedding_dim, hidden_dim, n_layers, drop_prob=0):\n",
        "        super(Net, self).__init__()\n",
        "\n",
        "        self.output_size = output_size\n",
        "        self.n_layers = n_layers\n",
        "        self.hidden_dim = hidden_dim\n",
        "\n",
        "        # embedding and LSTM layers\n",
        "        self.embedding = nn.Embedding(vocab_size, embedding_dim)\n",
        "        self.lstm = nn.LSTM(embedding_dim, hidden_dim, n_layers, dropout=drop_prob, batch_first=True)\n",
        "        #self.lstm = nn.LSTM(embedding_dim, hidden_dim, n_layers, batch_first=True)\n",
        "        # dropout layer\n",
        "        self.dropout = nn.Dropout(0.3)\n",
        "        \n",
        "        # linear and sigmoid layers\n",
        "        self.fc = nn.Linear(hidden_dim, output_size)\n",
        "        self.sig = nn.Sigmoid()\n",
        "\n",
        "    def forward(self, x, hidden):\n",
        "        x = x.cuda()\n",
        "        # embeddings and lstm_out\n",
        "        embeds = self.embedding(x)\n",
        "        lstm_out, hidden = self.lstm(embeds, hidden)\n",
        "    \n",
        "        # stack up lstm outputs\n",
        "        lstm_out = lstm_out.contiguous().view(-1, self.hidden_dim)\n",
        "        \n",
        "        # dropout and fully-connected layer\n",
        "        out = self.dropout(lstm_out)\n",
        "        out = self.fc(out)\n",
        "\n",
        "        # sigmoid function\n",
        "        sig_out = self.sig(out)\n",
        "        \n",
        "        # reshape to be batch_size first\n",
        "        sig_out = sig_out.view(batch_size,maxlen,-1)\n",
        "        \n",
        "        sig_out = sig_out[:, -1] # get last batch of labels\n",
        "        \n",
        "        # return last sigmoid output and hidden state\n",
        "        return sig_out, hidden\n",
        "\n",
        "\n",
        "    def init_hidden(self, batch_size):\n",
        "        ''' Initializes hidden state '''\n",
        "        # Create two new tensors with sizes n_layers x batch_size x hidden_dim,\n",
        "        # initialized to zero, for hidden state and cell state of LSTM\n",
        "        weight = next(self.parameters()).data\n",
        "        \n",
        "        if (train_on_gpu):\n",
        "            hidden = (weight.new(self.n_layers, batch_size, self.hidden_dim).zero_().cuda(),\n",
        "                  weight.new(self.n_layers, batch_size, self.hidden_dim).zero_().cuda())\n",
        "        else:\n",
        "            hidden = (weight.new(self.n_layers, batch_size, self.hidden_dim).zero_(),\n",
        "                      weight.new(self.n_layers, batch_size, self.hidden_dim).zero_())\n",
        "        \n",
        "        return hidden\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pWTPKikqY70c",
        "colab_type": "code",
        "outputId": "969c253e-7fad-44a4-8b89-1369981f8d53",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        }
      },
      "source": [
        "# Hyperparameters and initialization of model\n",
        "output_size = 5\n",
        "embedding_dim = 512\n",
        "hidden_dim = 512\n",
        "n_layers = 1\n",
        "net = Net(vocab_size, output_size, embedding_dim, hidden_dim, n_layers)\n",
        "print(net)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Net(\n",
            "  (embedding): Embedding(186446, 512)\n",
            "  (lstm): LSTM(512, 512, batch_first=True)\n",
            "  (dropout): Dropout(p=0.3, inplace=False)\n",
            "  (fc): Linear(in_features=512, out_features=5, bias=True)\n",
            "  (sig): Sigmoid()\n",
            ")\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XDAQdTX6DXwG",
        "colab_type": "code",
        "outputId": "6172f321-e1ec-4672-8d71-e275689c02c3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "# loss and optimization functions\n",
        "lr=0.0005\n",
        "\n",
        "criterion = nn.BCELoss()\n",
        "optimizer = torch.optim.Adam(net.parameters(), lr=lr, weight_decay=1e-5)\n",
        "\n",
        "# Add learning rate decay\n",
        "#scheduler = StepLR(optimizer, step_size=10, gamma=0.5)\n",
        "scheduler = ReduceLROnPlateau(optimizer, mode='min', factor=0.1, patience=3, verbose=True)\n",
        "\n",
        "# training params\n",
        "epochs = 9 # 3-4 is approx where I noticed the validation loss stop decreasing\n",
        "\n",
        "print_every = 1000\n",
        "clip=5 # gradient clipping\n",
        "\n",
        "train_on_gpu = torch.cuda.is_available()\n",
        "# move model to GPU, if available\n",
        "if(train_on_gpu):\n",
        "    net.cuda()\n",
        "\n",
        "# Track loss\n",
        "training_loss, validation_loss = [], []\n",
        "loss_list = []\n",
        "\n",
        "start_time = time.time()\n",
        "net.train()\n",
        "# train for some number of epochs\n",
        "for e in range(epochs):\n",
        "\n",
        "    # Track loss\n",
        "    epoch_training_loss = 0\n",
        "    epoch_validation_loss = 0\n",
        "\n",
        "    # For validation set\n",
        "    val_h = net.init_hidden(batch_size)\n",
        "    val_losses = []\n",
        "    net.eval()\n",
        "    for inputs, labels in valid_loader:\n",
        "\n",
        "        # Creating new variables for the hidden state\n",
        "        val_h = tuple([each.data for each in val_h])\n",
        "\n",
        "        if(train_on_gpu):\n",
        "            inputs, labels = inputs.cuda(), labels.cuda()\n",
        "\n",
        "        inputs = inputs.type(torch.LongTensor)\n",
        "        output, val_h = net(inputs, val_h)\n",
        "\n",
        "        val_loss = criterion(output.squeeze(), labels.float())\n",
        "\n",
        "        epoch_validation_loss += val_loss.detach().cpu().data.numpy()\n",
        "    \n",
        "    net.train()\n",
        "\n",
        "    # initialize hidden state\n",
        "    h = net.init_hidden(batch_size)\n",
        "\n",
        "    # For each review in training set\n",
        "    counter = 0\n",
        "    for inputs, labels in train_loader:\n",
        "        counter += 1\n",
        "        if counter % print_every == 0:\n",
        "            print(counter,\"Train\")\n",
        "\n",
        "        if(train_on_gpu):\n",
        "            inputs = inputs.cuda()\n",
        "            labels = labels.cuda()\n",
        "\n",
        "        # Creating new variables for the hidden state\n",
        "        h = tuple([each.data for each in h])\n",
        "\n",
        "        # zero accumulated gradients\n",
        "        net.zero_grad()\n",
        "\n",
        "        # get the output from the model\n",
        "        inputs = inputs.type(torch.LongTensor)\n",
        "        output, h = net(inputs, h)\n",
        "\n",
        "        # calculate the loss and perform backprop\n",
        "        loss = criterion(output.squeeze(), labels.float())\n",
        "        loss.backward()\n",
        "        # `clip_grad_norm` helps prevent the exploding gradient problem\n",
        "        nn.utils.clip_grad_norm_(net.parameters(), clip)\n",
        "        optimizer.step()\n",
        "\n",
        "        #Save loss\n",
        "        epoch_training_loss += loss.detach().cpu().data.numpy()\n",
        "\n",
        "    print('Epoch: ', e+1)\n",
        "    print('Time elapsed:', (time.time() - start_time)/60, 'minutes')\n",
        "    print('training loss:', epoch_training_loss / len(train_data)) # Divided by number of batches\n",
        "    print('validation loss:', epoch_validation_loss / len(valid_data))\n",
        "\n",
        "    scheduler.step(val_loss)\n",
        "\n",
        "    # Save loss for plot\n",
        "    training_loss.append(epoch_training_loss / len(train_data))\n",
        "    validation_loss.append(epoch_validation_loss / len(valid_data))\n",
        "\n",
        "# Plot training and validation loss of training and validation batches\n",
        "epoch = np.arange(len(training_loss))\n",
        "plt.figure()\n",
        "plt.plot(epoch, training_loss, 'r', label='Training loss',)\n",
        "plt.plot(epoch, validation_loss, 'b', label='Validation loss')\n",
        "plt.legend()\n",
        "plt.xlabel('Epoch'), plt.ylabel('loss')\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1000 Train\n",
            "2000 Train\n",
            "3000 Train\n",
            "Epoch:  1\n",
            "Time elapsed: 3.9256838083267214 minutes\n",
            "training loss: 0.007059185091471178\n",
            "validation loss: 0.014029917438477929\n",
            "1000 Train\n",
            "2000 Train\n",
            "3000 Train\n",
            "Epoch:  2\n",
            "Time elapsed: 7.863744513193766 minutes\n",
            "training loss: 0.006255598050912264\n",
            "validation loss: 0.006431848383366281\n",
            "1000 Train\n",
            "2000 Train\n",
            "3000 Train\n",
            "Epoch:  3\n",
            "Time elapsed: 11.806260935465495 minutes\n",
            "training loss: 0.006032064582941053\n",
            "validation loss: 0.006299225579963501\n",
            "1000 Train\n",
            "2000 Train\n",
            "3000 Train\n",
            "Epoch:  4\n",
            "Time elapsed: 15.75526260137558 minutes\n",
            "training loss: 0.0058689390787423695\n",
            "validation loss: 0.006244223345575374\n",
            "1000 Train\n",
            "2000 Train\n",
            "3000 Train\n",
            "Epoch:  5\n",
            "Time elapsed: 19.71751786470413 minutes\n",
            "training loss: 0.005716235090909306\n",
            "validation loss: 0.006126466646595293\n",
            "1000 Train\n",
            "2000 Train\n",
            "3000 Train\n",
            "Epoch:  6\n",
            "Time elapsed: 23.63071174621582 minutes\n",
            "training loss: 0.005569046550881785\n",
            "validation loss: 0.006056348633948372\n",
            "1000 Train\n",
            "2000 Train\n",
            "3000 Train\n",
            "Epoch:  7\n",
            "Time elapsed: 27.565089162190755 minutes\n",
            "training loss: 0.00538846130503187\n",
            "validation loss: 0.006053994280412207\n",
            "1000 Train\n",
            "2000 Train\n",
            "3000 Train\n",
            "Epoch:  8\n",
            "Time elapsed: 31.497539460659027 minutes\n",
            "training loss: 0.005187439557132372\n",
            "validation loss: 0.006109467979081333\n",
            "1000 Train\n",
            "2000 Train\n",
            "3000 Train\n",
            "Epoch:  9\n",
            "Time elapsed: 35.43301877975464 minutes\n",
            "training loss: 0.004927278371064163\n",
            "validation loss: 0.006211936287744597\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAY4AAAEGCAYAAABy53LJAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nKDhERCQl/x9b8uwKcpRvggAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9nKv94OBYyXN",
        "colab_type": "code",
        "outputId": "666e1859-99e4-4731-9690-2981dad8c2fd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "# Get test data loss and accuracy\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "test_losses = [] # track loss\n",
        "pred_list = []\n",
        "correct_list = []\n",
        "\n",
        "# init hidden state\n",
        "h = net.init_hidden(batch_size)\n",
        "\n",
        "net.eval()\n",
        "# iterate over test data\n",
        "for inputs, labels in test_loader:\n",
        "\n",
        "    # Creating new variables for the hidden state\n",
        "    h = tuple([each.data for each in h])\n",
        "\n",
        "    if(train_on_gpu):\n",
        "        inputs, labels = inputs.cuda(), labels.cuda()\n",
        "    \n",
        "    # get predicted outputs\n",
        "    inputs = inputs.type(torch.LongTensor)\n",
        "    output, h = net(inputs, h)\n",
        "    \n",
        "    # calculate loss\n",
        "    test_loss = criterion(output.squeeze(), labels.float())\n",
        "    test_losses.append(test_loss.item())\n",
        "    \n",
        "    # convert output to rating\n",
        "    output_array = output.cpu().data.numpy()\n",
        "    pred = np.argmax(output_array, axis=1) + 1 # rounds to the nearest integer\n",
        "    pred_list = np.concatenate((pred_list, pred))\n",
        "    \n",
        "    # compare predictions to true label\n",
        "    label_array = labels.cpu().data.numpy()\n",
        "    correct = np.argmax(label_array, axis=1) + 1# rounds to the nearest integer\n",
        "    correct_list = np.concatenate((correct_list, correct))\n",
        "\n",
        "# -- stats! -- ##\n",
        "# avg test loss\n",
        "print(\"Test loss: {:.3f}\".format(np.mean(test_losses)))\n",
        "\n",
        "# accuracy over all test data\n",
        "test_acc = accuracy_score(correct_list,pred_list)\n",
        "print(\"Test accuracy: {:.3f}\".format(test_acc))\n",
        "\n",
        "# accuracy when tolerating a difference of 1\n",
        "diff = correct_list - pred_list\n",
        "test_acc_oneoff = sum(np.absolute(diff) < 2) / len(diff)\n",
        "print(\"Test accuracy: {:.3f}\".format(test_acc_oneoff))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test loss: 0.306\n",
            "Test accuracy: 0.617\n",
            "Test accuracy: 0.958\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rm66NWllJWpH",
        "colab_type": "code",
        "outputId": "8731655e-c364-4795-c24d-4ae1a422dfe5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# Test on custom reviews\n",
        "test_review = 'If you are looking for food poisoning this is the perfect place to be'\n",
        "\n",
        "test_review = preprocess_text(test_review)\n",
        "test_review = tokenizer.texts_to_sequences([test_review])\n",
        "test_review = pad_sequences(test_review, padding='pre', maxlen=maxlen)\n",
        "\n",
        "feature_tensor = torch.tensor(test_review).to(torch.int64)\n",
        "\n",
        "batch_size = feature_tensor.size(0)\n",
        "\n",
        "# initialize hidden state\n",
        "h = net.init_hidden(batch_size)\n",
        "net.eval()\n",
        "\n",
        "h = tuple([each.data for each in h])\n",
        "\n",
        "if(train_on_gpu):\n",
        "    inputs = feature_tensor.cuda()\n",
        "    \n",
        "# get the output from the model\n",
        "output, h = net(inputs, h)\n",
        "\n",
        "output_array = output.cpu().data.numpy()\n",
        "pred = np.argmax(output_array, axis=1) + 1 # rounds to the nearest integer\n",
        "\n",
        "print('Predicted rating:', pred)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Predicted rating: [5]\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}